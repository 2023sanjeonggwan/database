{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\may_2\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\may_2\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\may_2\\anaconda3\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\may_2\\anaconda3\\lib\\site-packages (4.15.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from selenium) (0.23.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: idna in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDU_UIDRNlJ3",
    "outputId": "d579b3a4-d72c-4a35-b00b-0cd870a1179d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journalists information saved to journalists_info_032.csv.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def crawl_journalist_info(office_id):\n",
    "    url = f'https://media.naver.com/journalists/whole?officeId={office_id}'\n",
    "    \n",
    "    driver = webdriver.Chrome()  # Change to the appropriate driver based on your browser.\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the page to load (adjust as needed)\n",
    "    driver.implicitly_wait(5)\n",
    "    \n",
    "    journalist_list = []\n",
    "\n",
    "    while True:\n",
    "        # Get the initial page height\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        # Scroll to the bottom of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        # Wait for a short moment to let the page content load\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "\n",
    "        # Update last height for the next iteration\n",
    "        last_height = new_height\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    for journalist_item in soup.select('.journalist_list_content_body'):\n",
    "        # 1. 기자 식별번호(JournalistNumber)와 기자 이름(Journalist) 추출\n",
    "        subscribe_channel_key = journalist_item.select_one('.subscribe._my_feed_btn')['data-subscribechannelkey']\n",
    "        journalist_number = subscribe_channel_key.split('_')[-1]\n",
    "\n",
    "        subscribe_name = journalist_item.select_one('.subscribe._my_feed_btn')['data-subscribename']\n",
    "        journalist_name = subscribe_name\n",
    "\n",
    "        # 2. 소속 언론사(Press) 추출\n",
    "        press_tag = journalist_item.select_one('.journalist_list_content_info_item')\n",
    "        press = press_tag.get_text(strip=True) if press_tag else ''\n",
    "\n",
    "        # 3. 카테고리(Category) 추출\n",
    "        category_tag = press_tag.find_next('span')\n",
    "        category = category_tag.get_text(strip=True) if category_tag else ''\n",
    "\n",
    "        # 정보를 딕셔너리로 저장\n",
    "        journalist_info = {\n",
    "            'JournalistNumber': journalist_number,\n",
    "            'Journalist': journalist_name,\n",
    "            'Press': press,\n",
    "            'Category': category\n",
    "        }\n",
    "\n",
    "        journalist_list.append(journalist_info)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return journalist_list\n",
    "\n",
    "# officeId에 언론사 식별번호를 지정하여 크롤링 실행\n",
    "office_id = '032'  # 예시로 '경향신문' 언론사의 officeId를 사용했습니다. 원하는 언론사의 officeId로 변경하세요.\n",
    "journalists_info = crawl_journalist_info(office_id)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df = pd.DataFrame(journalists_info)\n",
    "\n",
    "# DataFrame을 CSV 파일로 저장\n",
    "csv_filename = f'journalists_info_{office_id}.csv'\n",
    "df.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'Journalists information saved to {csv_filename}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "EZm2gq_XR9dT",
    "outputId": "08e89a01-1d98-410e-e1db-10b248a70145"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JournalistNumber</th>\n",
       "      <th>Journalist</th>\n",
       "      <th>Press</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76306</td>\n",
       "      <td>이두리</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72194</td>\n",
       "      <td>박상영</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73769</td>\n",
       "      <td>김은성</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74935</td>\n",
       "      <td>조해람</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78499</td>\n",
       "      <td>김나연</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78584</td>\n",
       "      <td>김서영</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>세계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56121</td>\n",
       "      <td>박경은</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>생활/문화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73386</td>\n",
       "      <td>박광연</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79474</td>\n",
       "      <td>유새슬</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62118</td>\n",
       "      <td>반기웅</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>78502</td>\n",
       "      <td>신주영</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>74633</td>\n",
       "      <td>이정호</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>생활/문화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56163</td>\n",
       "      <td>이성희</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>73907</td>\n",
       "      <td>박준철</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>75929</td>\n",
       "      <td>민서영</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>73770</td>\n",
       "      <td>선명수</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>세계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>73512</td>\n",
       "      <td>탁지영</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>76180</td>\n",
       "      <td>김태희</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73783</td>\n",
       "      <td>구교형</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56201</td>\n",
       "      <td>강현석</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    JournalistNumber Journalist Press Category\n",
       "0              76306        이두리  경향신문       정치\n",
       "1              72194        박상영  경향신문       경제\n",
       "2              73769        김은성  경향신문       경제\n",
       "3              74935        조해람  경향신문       사회\n",
       "4              78499        김나연  경향신문       사회\n",
       "5              78584        김서영  경향신문       세계\n",
       "6              56121        박경은  경향신문    생활/문화\n",
       "7              73386        박광연  경향신문       정치\n",
       "8              79474        유새슬  경향신문       정치\n",
       "9              62118        반기웅  경향신문       경제\n",
       "10             78502        신주영  경향신문       정치\n",
       "11             74633        이정호  경향신문    생활/문화\n",
       "12             56163        이성희  경향신문       사회\n",
       "13             73907        박준철  경향신문       경제\n",
       "14             75929        민서영  경향신문       사회\n",
       "15             73770        선명수  경향신문       세계\n",
       "16             73512        탁지영  경향신문       정치\n",
       "17             76180        김태희  경향신문       사회\n",
       "18             73783        구교형  경향신문       경제\n",
       "19             56201        강현석  경향신문       사회"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "csv_path = 'C:/Users/may_2/Documents/23-2 산정관/팀플/모으기/journalists_info_032.csv'  # 파일 경로에 맞게 수정하세요.\n",
    "df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "\n",
    "# 데이터프레임 출력\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\may_2\\anaconda3\\lib\\site-packages (4.15.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from selenium) (0.23.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: outcome in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: idna in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\may_2\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Crawling Journalist Data: 100%|██████████████████████████████████████████████████████████| 5/5 [00:39<00:00,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journalist data saved to C:/Users/may_2/Documents/23-2 산정관/팀플/모으기/journalist_result_032.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def crawl_journalist_data(journalist_info, press_mapping):\n",
    "    journalist_number = journalist_info['JournalistNumber']\n",
    "    journalist_name = journalist_info['Journalist']\n",
    "    press_name = journalist_info['Press']\n",
    "\n",
    "    # PressNumber 찾기\n",
    "    press_number = press_mapping.get(press_name, '')\n",
    "\n",
    "    # PressNumber가 없으면 크롤링을 진행하지 않음\n",
    "    if not press_number:\n",
    "        print(f\"Skipping {journalist_name} from {press_name}\")\n",
    "        return None\n",
    "\n",
    "    # 크롤링할 사이트 주소\n",
    "    url = f'https://media.naver.com/journalist/{press_number}/{journalist_number}'\n",
    "\n",
    "    # 웹드라이버 설정 (Chrome 드라이버 사용)\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # 이메일 주소 추출\n",
    "        try:\n",
    "            email_element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.media_reporter_email')))\n",
    "            email = email_element.get_attribute('href').split(':')[1]\n",
    "        except Exception as e:\n",
    "            email = ''\n",
    "            print(f\"Error extracting email for {journalist_name}: {str(e)}\")\n",
    "\n",
    "        # 기사 작성 건수 추출\n",
    "        try:\n",
    "            summary_element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.media_reporter_summary_item em')))\n",
    "            monthly_article_written = int(summary_element.text.split()[1])\n",
    "        except Exception as e:\n",
    "            monthly_article_written = ''\n",
    "            print(f\"Error extracting monthly article count for {journalist_name}: {str(e)}\")\n",
    "\n",
    "        # 결과 반환\n",
    "        result = {\n",
    "            'JournalistNumber': journalist_number,\n",
    "            'Journalist': journalist_name,\n",
    "            'PressNumber': press_number,\n",
    "            'Email': email,\n",
    "            'MonthlyArticleWritten': monthly_article_written\n",
    "        }\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error crawling data for {journalist_name}: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# CSV 파일 읽기\n",
    "csv_path = 'C:/Users/may_2/Documents/23-2 산정관/팀플/모으기/journalists_info_032x.csv'\n",
    "df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "\n",
    "# 언론사 대상을 설정하는 매핑\n",
    "press_mapping = {\n",
    "    '중앙일보': '025',\n",
    "    '조선일보': '023',\n",
    "    '한겨레': '028',\n",
    "    '동아일보': '020',\n",
    "    '경향신문': '032'\n",
    "}\n",
    "\n",
    "# 크롤링 결과를 저장할 리스트\n",
    "journalist_data_list = []\n",
    "\n",
    "# tqdm을 이용한 진행 상황 로딩바 표시\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc='Crawling Journalist Data'):\n",
    "    journalist_data = crawl_journalist_data(row, press_mapping)\n",
    "    if journalist_data:\n",
    "        journalist_data_list.append(journalist_data)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "result_df = pd.DataFrame(journalist_data_list)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "result_csv_path = 'C:/Users/may_2/Documents/23-2 산정관/팀플/모으기/journalist_result_032.csv'\n",
    "result_df.to_csv(result_csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'Journalist data saved to {result_csv_path}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
